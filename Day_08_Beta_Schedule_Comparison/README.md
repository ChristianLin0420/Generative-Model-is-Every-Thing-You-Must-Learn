# Day 8: Beta Schedule Comparison for DDPM

A comprehensive comparison framework for analyzing different noise schedules (Î²-schedules) in Denoising Diffusion Probabilistic Models and their impact on training dynamics and sample quality.

## ğŸ¯ Project Overview

This project implements and compares three key beta schedules used in diffusion models:
- **Linear**: Uniform noise addition progression
- **Cosine**: Preserves signal longer in early timesteps  
- **Quadratic**: Aggressive early noise corruption

## ğŸš€ Quick Start

```bash
# Setup environment
make setup

# Train all three schedules
make train_all

# Generate samples and visualizations
make sample_all

# Compare results and generate report
make compare

# Run tests
make test
```

## ğŸ“ Project Structure

```
Day_08_Beta_Schedule_Comparison/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Makefile                               # setup | train_all | sample_all | compare | test
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ base.yaml                          # Common settings (dataset/model/T/optimizer)
â”‚   â”œâ”€â”€ linear.yaml                        # Linear schedule config
â”‚   â”œâ”€â”€ cosine.yaml                        # Cosine schedule config
â”‚   â””â”€â”€ quadratic.yaml                     # Quadratic schedule config
â”œâ”€â”€ data/                                  # Auto-downloaded by torchvision
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py                           # Seeding, device, ckpt I/O, timers, grid/gif savers
â”‚   â”œâ”€â”€ dataset.py                         # MNIST/CIFAR loaders, normalization, labels (opt)
â”‚   â”œâ”€â”€ schedules.py                       # Î² schedulers: linear/cosine/quadratic + Î±, á¾±, SNR
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ time_embedding.py              # Sinusoidal + MLP
â”‚   â”‚   â””â”€â”€ unet_small.py                  # UNet architecture for apples-to-apples comparison
â”‚   â”œâ”€â”€ losses.py                          # DDPM Îµ-prediction loss
â”‚   â”œâ”€â”€ trainer.py                         # Training loop w/ AMP, EMA, LR schedule, periodic sampling
â”‚   â”œâ”€â”€ sampler.py                         # DDPM ancestral + DDIM(Î·=0) sampler
â”‚   â”œâ”€â”€ visualize.py                       # Schedule plots; trajectory grids; animations
â”‚   â”œâ”€â”€ quality.py                         # FID-proxy, PSNR/SSIM/LPIPS, step-time logging
â”‚   â””â”€â”€ cli.py                             # train | sample | plot.schedules | compare
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_all.sh                       # Trains 3 schedules (linear/cosine/quadratic)
â”‚   â”œâ”€â”€ sample_all.sh                      # Samples grids + animations for each schedule
â”‚   â””â”€â”€ compare.sh                         # Computes metrics & renders comparison report
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 08_beta_schedule_playground.ipynb  # Interactive T & schedule tweaking
â”œâ”€â”€ outputs/                               # Generated during training/evaluation
â”‚   â”œâ”€â”€ linear/
â”‚   â”‚   â”œâ”€â”€ ckpts/ logs/ curves/ grids/ animations/
â”‚   â”œâ”€â”€ cosine/
â”‚   â”‚   â”œâ”€â”€ ckpts/ logs/ curves/ grids/ animations/
â”‚   â”œâ”€â”€ quadratic/
â”‚   â”‚   â”œâ”€â”€ ckpts/ logs/ curves/ grids/ animations/
â”‚   â”œâ”€â”€ plots/                             # Schedule comparison plots
â”‚   â””â”€â”€ comparison/                        # Cross-schedule analysis
â””â”€â”€ tests/
    â”œâ”€â”€ test_schedules_shapes.py           # Î²âˆˆ(0,1), á¾± monotoneâ†“, shapes OK for all schedules
    â”œâ”€â”€ test_training_smoke.py             # 1-2 steps reduce loss for each schedule
    â”œâ”€â”€ test_sampler_smoke.py              # Reverse pass shapes, no NaNs
    â””â”€â”€ test_visualize.py                  # Schedule plot + grid + GIF write
```

## ğŸ§® Beta Schedule Formulations

### Linear Schedule
```python
Î²_t = Î²_min + (Î²_max - Î²_min) * t/T
```
- **Default**: Î²_min = 1e-4, Î²_max = 0.02
- Simple, uniform noise addition

### Cosine Schedule  
```python
Î±Ì…_t = cosÂ²(Ï€/2 * (t/T + s)/(1 + s))
Î²_t = 1 - Î±Ì…_t/Î±Ì…_{t-1}
```
- **Parameter**: s = 0.008 (small offset)
- Slower early diffusion, preserves fine details

### Quadratic Schedule
```python
Î²_t = Î²_min + (Î²_max - Î²_min) * (t/T)Â²
```
- Quadratic progression
- Faster early noise addition

## ğŸ® Usage Examples

### Training Individual Schedules
```bash
# Train with specific schedule
python -m src.cli train --config configs/linear.yaml
python -m src.cli train --config configs/cosine.yaml
python -m src.cli train --config configs/quadratic.yaml
```

### Sample Generation
```bash
# Generate DDPM samples
python -m src.cli sample.grid --config configs/cosine.yaml

# Generate DDIM samples (faster)
python -m src.cli sample.grid --config configs/cosine.yaml --ddim

# Generate trajectory visualization
python -m src.cli sample.traj --config configs/cosine.yaml
```

### Visualization & Analysis
```bash
# Plot schedule comparison
python -m src.cli plot.schedules --configs configs/linear.yaml configs/cosine.yaml configs/quadratic.yaml

# Full comparison with metrics
python -m src.cli compare --configs configs/linear.yaml configs/cosine.yaml configs/quadratic.yaml
```

## ğŸ“Š Expected Deliverables

After running the complete pipeline, you'll obtain:

### âœ… **Trained Models**
- `outputs/{linear,cosine,quadratic}/ckpts/ema.pt`
- `outputs/{linear,cosine,quadratic}/ckpts/best.pt`

### âœ… **Visualizations**
- `outputs/plots/schedules_overlay.png` - Î², á¾±, and SNR overlays
- `outputs/{run}/grids/samples_ema.png` - Sample grids (â‰¥64 samples)
- `outputs/{run}/animations/reverse_traj.gif` - Reverse diffusion Tâ†’0
- `outputs/{run}/grids/trajectory_grid.png` - Fixed sample across time steps

### âœ… **Metrics & Comparison**
- `outputs/{run}/logs/metrics.csv` - Training loss, PSNR/SSIM, time/iter
- `outputs/comparison/comparison.csv` - Cross-schedule metrics (FID-proxy, LPIPS, PSNR, SSIM, steps/sec)
- `outputs/comparison/quality_vs_schedule.png` - Quality comparison plots
- `outputs/comparison/report.md` - Key findings and insights

### âœ… **Tests Pass**
- Schedule validity tests (Î²âˆˆ(0,1), á¾± monotone decreasing)
- Training smoke tests (loss reduction)
- Sampling functionality tests
- Visualization pipeline tests

## ğŸ” Key Insights

### **Linear Schedule**
- âœ… Simple implementation and interpretation
- âœ… Good baseline for comparison
- âš ï¸ May not be optimal for fine detail preservation

### **Cosine Schedule**  
- âœ… Slower early SNR decay preserves fine details longer
- âœ… Often produces higher quality samples
- âœ… Better for image generation tasks
- âš ï¸ Slightly more complex implementation

### **Quadratic Schedule**
- âœ… Faster training convergence possible
- âœ… Aggressive noise corruption
- âš ï¸ May sacrifice fine detail quality
- âš ï¸ Steep early SNR decline

## ğŸ“ Learning Outcomes

- **Schedule Impact**: Understanding how Î²-schedule choice affects diffusion dynamics
- **Training Analysis**: Experience with comparing training curves and convergence
- **Quality Metrics**: Hands-on experience with FID, PSNR, SSIM evaluation
- **Hyperparameter Sensitivity**: Insights into schedule parameter effects
- **Implementation Skills**: Building modular, configurable diffusion frameworks

## ğŸ§ª Interactive Exploration

Explore schedules interactively in the Jupyter notebook:

```bash
cd notebooks/
jupyter notebook 08_beta_schedule_playground.ipynb
```

Features:
- ğŸ”¬ Interactive parameter adjustment (T, Î²_min, Î²_max, cosine_s)
- ğŸ“Š Real-time schedule visualization (Î²_t, á¾±_t, SNR curves)
- ğŸ¯ Forward diffusion process visualization
- ğŸ§ª Custom schedule designer
- ğŸ“ˆ Mathematical property analysis

## ğŸ“– Technical References

- **Improved DDPM** (Nichol & Dhariwal, 2021) - Cosine schedule introduction
- **DDPM** (Ho et al., 2020) - Original linear schedule formulation  
- **DDIM** (Song et al., 2020) - Deterministic sampling with schedule flexibility

## ğŸ› ï¸ Configuration

All configurations use YAML with inheritance:

**Base Config** (`configs/base.yaml`):
```yaml
seed: 808
device: "cuda:0"
data: { dataset: "mnist", batch_size: 128, normalize: "minus_one_one" }
diffusion: { T: 1000, schedule: "cosine" }
model: { in_ch: 1, base_ch: 64, ch_mult: [1,2,2], time_embed_dim: 256 }
train: { epochs: 40, lr: 2e-4, opt: "adamw", ema: true, amp: true }
sample: { num_images: 64, ddim_steps: 50 }
```

**Schedule-Specific** configs inherit base and override `diffusion.schedule` and `log.run_name`.

---

**Time Estimate**: 4-6 hours (including training)  
**Difficulty**: â­â­â­â­â˜†  
**Prerequisites**: Understanding of DDPM fundamentals