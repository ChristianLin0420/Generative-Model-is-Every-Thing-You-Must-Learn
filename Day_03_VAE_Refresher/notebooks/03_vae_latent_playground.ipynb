{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# VAE Latent Space Playground üéÆ\n",
        "\n",
        "This notebook provides an interactive environment for exploring VAE latent spaces, visualizing ELBO components, and experimenting with different VAE configurations.\n",
        "\n",
        "## üìö What You'll Learn\n",
        "- How to load and interact with trained VAE models\n",
        "- Explore latent space through traversals and interpolations\n",
        "- Understand ELBO decomposition (reconstruction + KL divergence)\n",
        "- Compare different sampling strategies\n",
        "- Visualize the learned latent representations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('../')\n",
        "\n",
        "from src.eval import load_model_from_checkpoint\n",
        "from src.dataset import get_sample_images\n",
        "from src.visualize import create_latent_traversal, create_reconstruction_grid\n",
        "from src.sample import sample_from_prior, interpolate_between_samples\n",
        "from src.losses import elbo_loss\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Load Trained VAE Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "‚úÖ Model loaded successfully!\n",
            "Model: VAEConv\n",
            "Dataset: mnist\n",
            "Latent dimensions: 32\n",
            "Input channels: 1\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "CHECKPOINT_PATH = \"../outputs/ckpts/best.pt\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load model\n",
        "try:\n",
        "    model, config = load_model_from_checkpoint(CHECKPOINT_PATH, device)\n",
        "    print(f\"‚úÖ Model loaded successfully!\")\n",
        "    print(f\"Model: {model.__class__.__name__}\")\n",
        "    print(f\"Dataset: {config.data.dataset}\")\n",
        "    print(f\"Latent dimensions: {model.latent_dim}\")\n",
        "    print(f\"Input channels: {config.model.in_ch}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Checkpoint not found: {CHECKPOINT_PATH}\")\n",
        "    print(f\"üí° Please train a model first using: python -m src.cli train --config configs/mnist.yaml\")\n",
        "    model, config = None, None\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model: {e}\")\n",
        "    model, config = None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Load Sample Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample images shape: torch.Size([64, 1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x300 with 16 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if model is not None and config is not None:\n",
        "    # Load sample images\n",
        "    sample_images = get_sample_images(\n",
        "        config.data.dataset,\n",
        "        config.data.root,\n",
        "        num_samples=64,\n",
        "        normalize=config.data.normalize\n",
        "    )\n",
        "    \n",
        "    print(f\"Sample images shape: {sample_images.shape}\")\n",
        "    \n",
        "    # Display a few sample images\n",
        "    fig, axes = plt.subplots(2, 8, figsize=(12, 3))\n",
        "    for i in range(16):\n",
        "        row, col = i // 8, i % 8\n",
        "        img = sample_images[i].squeeze().cpu().numpy()\n",
        "        axes[row, col].imshow(img, cmap='gray' if config.model.in_ch == 1 else None)\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    plt.suptitle('Sample Images from Dataset')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping data loading (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîÑ Interactive Reconstruction Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model is not None:\n",
        "    def show_reconstruction(image_idx=0):\n",
        "        \"\"\"Show original vs reconstructed image.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            \n",
        "            # Get original image\n",
        "            original = sample_images[image_idx:image_idx+1].to(device)\n",
        "            \n",
        "            # Get reconstruction\n",
        "            reconstruction = model.reconstruct(original)\n",
        "            \n",
        "            # Compute ELBO components\n",
        "            x_hat, mu, logvar = model(original)\n",
        "            _, loss_dict = elbo_loss(x_hat, original, mu, logvar, beta=1.0, \n",
        "                                   recon_loss_type=config.train.recon_loss)\n",
        "            \n",
        "            # Display\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "            \n",
        "            # Original\n",
        "            orig_img = original.squeeze().cpu().numpy()\n",
        "            axes[0].imshow(orig_img, cmap='gray' if config.model.in_ch == 1 else None)\n",
        "            axes[0].set_title('Original')\n",
        "            axes[0].axis('off')\n",
        "            \n",
        "            # Reconstruction\n",
        "            if hasattr(model, 'decoder') and hasattr(model.decoder, 'deconv_layers'):\n",
        "                recon_img = torch.sigmoid(reconstruction).squeeze().cpu().numpy()\n",
        "            else:\n",
        "                recon_img = reconstruction.squeeze().cpu().numpy()\n",
        "            \n",
        "            axes[1].imshow(recon_img, cmap='gray' if config.model.in_ch == 1 else None)\n",
        "            axes[1].set_title('Reconstruction')\n",
        "            axes[1].axis('off')\n",
        "            \n",
        "            # Add loss information\n",
        "            plt.suptitle(f'Recon Loss: {loss_dict[\"recon_loss\"].item():.3f}, '\n",
        "                        f'KL Loss: {loss_dict[\"kl_loss\"].item():.3f}, '\n",
        "                        f'Total: {loss_dict[\"total_loss\"].item():.3f}')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Show latent statistics\n",
        "            print(f\"Latent statistics:\")\n",
        "            print(f\"  Mean (Œº): min={mu.min().item():.3f}, max={mu.max().item():.3f}, std={mu.std().item():.3f}\")\n",
        "            print(f\"  Log-var: min={logvar.min().item():.3f}, max={logvar.max().item():.3f}, mean={logvar.mean().item():.3f}\")\n",
        "            print(f\"  Std (œÉ): min={torch.exp(0.5*logvar).min().item():.3f}, max={torch.exp(0.5*logvar).max().item():.3f}\")\n",
        "    \n",
        "    # Interactive widget\n",
        "    interact(show_reconstruction, image_idx=widgets.IntSlider(\n",
        "        value=0, min=0, max=len(sample_images)-1, step=1, description='Image:'))\n",
        "        \n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping reconstruction demo (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéöÔ∏è Interactive Latent Space Traversal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6af2225b0ffa44cbbff7b1d990af025c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='Image:', max=63), IntSlider(value=0, description='Dimens‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if model is not None:\n",
        "    def traverse_latent_space(image_idx=0, dim=0, num_steps=11, step_size=3.0):\n",
        "        \"\"\"Interactive latent space traversal.\"\"\"\n",
        "        if dim >= model.latent_dim:\n",
        "            print(f\"‚ö†Ô∏è Dimension {dim} is out of range. Model has {model.latent_dim} dimensions.\")\n",
        "            return\n",
        "            \n",
        "        base_image = sample_images[image_idx:image_idx+1].to(device)\n",
        "        \n",
        "        # Create traversal\n",
        "        traversal = create_latent_traversal(\n",
        "            model, base_image, device, dim, num_steps, step_size\n",
        "        )\n",
        "        \n",
        "        # Display traversal\n",
        "        fig, axes = plt.subplots(1, num_steps, figsize=(2*num_steps, 2))\n",
        "        if num_steps == 1:\n",
        "            axes = [axes]\n",
        "            \n",
        "        traverse_values = np.linspace(-step_size, step_size, num_steps)\n",
        "        \n",
        "        for i in range(num_steps):\n",
        "            img = traversal[i].squeeze().cpu().numpy()\n",
        "            axes[i].imshow(img, cmap='gray' if config.model.in_ch == 1 else None)\n",
        "            axes[i].set_title(f'{traverse_values[i]:.1f}')\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Latent Traversal - Dimension {dim}')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Interactive widget\n",
        "    interact(traverse_latent_space, \n",
        "             image_idx=widgets.IntSlider(value=0, min=0, max=len(sample_images)-1, description='Image:'),\n",
        "             dim=widgets.IntSlider(value=0, min=0, max=min(model.latent_dim-1, 15), description='Dimension:'),\n",
        "             num_steps=widgets.IntSlider(value=11, min=3, max=15, description='Steps:'),\n",
        "             step_size=widgets.FloatSlider(value=3.0, min=0.5, max=5.0, step=0.5, description='Range:'))\n",
        "             \n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping latent traversal demo (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üé≤ Interactive Prior Sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f00b1dd112c4469eb8e3857bda327a98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=16, description='# Samples:', max=64, min=4, step=4), FloatSlider(value=‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if model is not None:\n",
        "    def sample_from_prior_interactive(num_samples=16, temperature=1.0, seed=42):\n",
        "        \"\"\"Generate samples from prior with different temperatures.\"\"\"\n",
        "        torch.manual_seed(seed)\n",
        "        \n",
        "        samples = sample_from_prior(model, num_samples, device, temperature)\n",
        "        \n",
        "        # Display samples\n",
        "        grid_size = int(np.ceil(np.sqrt(num_samples)))\n",
        "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(2*grid_size, 2*grid_size))\n",
        "        \n",
        "        if grid_size == 1:\n",
        "            axes = [[axes]]\n",
        "        elif len(axes.shape) == 1:\n",
        "            axes = [axes]\n",
        "        \n",
        "        for i in range(grid_size):\n",
        "            for j in range(grid_size):\n",
        "                idx = i * grid_size + j\n",
        "                if idx < num_samples:\n",
        "                    img = samples[idx].squeeze().cpu().numpy()\n",
        "                    axes[i][j].imshow(img, cmap='gray' if config.model.in_ch == 1 else None)\n",
        "                axes[i][j].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Samples from Prior (Temperature: {temperature})')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Interactive widget\n",
        "    interact(sample_from_prior_interactive,\n",
        "             num_samples=widgets.IntSlider(value=16, min=4, max=64, step=4, description='# Samples:'),\n",
        "             temperature=widgets.FloatSlider(value=1.0, min=0.1, max=2.0, step=0.1, description='Temperature:'),\n",
        "             seed=widgets.IntSlider(value=42, min=0, max=9999, description='Seed:'))\n",
        "             \n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping prior sampling demo (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üåà Interactive Interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ffbb4b37d2e48909a28921747c4dbec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='Image 1:', max=63), IntSlider(value=10, description='Ima‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if model is not None:\n",
        "    def interpolate_interactive(img1_idx=0, img2_idx=10, num_steps=10, mode='linear'):\n",
        "        \"\"\"Interpolate between two images.\"\"\"\n",
        "        if img1_idx == img2_idx:\n",
        "            print(\"‚ö†Ô∏è Please select different images for interpolation.\")\n",
        "            return\n",
        "            \n",
        "        img1 = sample_images[img1_idx:img1_idx+1].to(device)\n",
        "        img2 = sample_images[img2_idx:img2_idx+1].to(device)\n",
        "        \n",
        "        # Create interpolation\n",
        "        interpolated = interpolate_between_samples(\n",
        "            model, img1, img2, num_steps, mode\n",
        "        )\n",
        "        \n",
        "        # Display interpolation\n",
        "        fig, axes = plt.subplots(1, num_steps, figsize=(2*num_steps, 2))\n",
        "        if num_steps == 1:\n",
        "            axes = [axes]\n",
        "        \n",
        "        alphas = np.linspace(0, 1, num_steps)\n",
        "        \n",
        "        for i in range(num_steps):\n",
        "            img = interpolated[i].squeeze().cpu().numpy()\n",
        "            axes[i].imshow(img, cmap='gray' if config.model.in_ch == 1 else None)\n",
        "            axes[i].set_title(f'{alphas[i]:.2f}')\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Interpolation ({mode}): Image {img1_idx} ‚Üí Image {img2_idx}')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Interactive widget\n",
        "    interact(interpolate_interactive,\n",
        "             img1_idx=widgets.IntSlider(value=0, min=0, max=len(sample_images)-1, description='Image 1:'),\n",
        "             img2_idx=widgets.IntSlider(value=10, min=0, max=len(sample_images)-1, description='Image 2:'),\n",
        "             num_steps=widgets.IntSlider(value=10, min=3, max=15, description='Steps:'),\n",
        "             mode=widgets.Dropdown(options=['linear', 'spherical'], value='linear', description='Mode:'))\n",
        "             \n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping interpolation demo (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìà ELBO Components Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "088a5ea7f860418ab4e7f90c14531d0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=50, description='# Samples:', max=64, min=10, step=10), FloatSlider(valu‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if model is not None:\n",
        "    def analyze_elbo_components(num_samples=100, beta=1.0):\n",
        "        \"\"\"Analyze ELBO components across multiple samples.\"\"\"\n",
        "        model.eval()\n",
        "        \n",
        "        recon_losses = []\n",
        "        kl_losses = []\n",
        "        total_losses = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for i in range(min(num_samples, len(sample_images))):\n",
        "                x = sample_images[i:i+1].to(device)\n",
        "                x_hat, mu, logvar = model(x)\n",
        "                \n",
        "                _, loss_dict = elbo_loss(x_hat, x, mu, logvar, beta, \n",
        "                                       config.train.recon_loss)\n",
        "                \n",
        "                recon_losses.append(loss_dict['recon_loss'].item())\n",
        "                kl_losses.append(loss_dict['kl_loss'].item())\n",
        "                total_losses.append(loss_dict['total_loss'].item())\n",
        "        \n",
        "        # Create plots\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "        \n",
        "        # Histogram of losses\n",
        "        axes[0, 0].hist(recon_losses, alpha=0.7, label='Reconstruction', bins=20)\n",
        "        axes[0, 0].hist(kl_losses, alpha=0.7, label='KL Divergence', bins=20)\n",
        "        axes[0, 0].set_xlabel('Loss Value')\n",
        "        axes[0, 0].set_ylabel('Frequency')\n",
        "        axes[0, 0].set_title('Loss Distribution')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Scatter plot: Reconstruction vs KL\n",
        "        axes[0, 1].scatter(recon_losses, kl_losses, alpha=0.6)\n",
        "        axes[0, 1].set_xlabel('Reconstruction Loss')\n",
        "        axes[0, 1].set_ylabel('KL Loss')\n",
        "        axes[0, 1].set_title('Reconstruction vs KL Loss')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Total loss over samples\n",
        "        axes[1, 0].plot(total_losses, alpha=0.7)\n",
        "        axes[1, 0].set_xlabel('Sample Index')\n",
        "        axes[1, 0].set_ylabel('Total Loss')\n",
        "        axes[1, 0].set_title('Total Loss per Sample')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Loss components comparison\n",
        "        loss_means = [np.mean(recon_losses), np.mean(kl_losses)]\n",
        "        loss_stds = [np.std(recon_losses), np.std(kl_losses)]\n",
        "        loss_names = ['Reconstruction', 'KL Divergence']\n",
        "        \n",
        "        bars = axes[1, 1].bar(loss_names, loss_means, yerr=loss_stds, capsize=5)\n",
        "        axes[1, 1].set_ylabel('Average Loss')\n",
        "        axes[1, 1].set_title('Average Loss Components')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Color bars differently\n",
        "        bars[0].set_color('skyblue')\n",
        "        bars[1].set_color('lightcoral')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print statistics\n",
        "        print(f\"üìä ELBO Statistics (Œ≤={beta}):\")\n",
        "        print(f\"  Reconstruction Loss: {np.mean(recon_losses):.3f} ¬± {np.std(recon_losses):.3f}\")\n",
        "        print(f\"  KL Divergence:       {np.mean(kl_losses):.3f} ¬± {np.std(kl_losses):.3f}\")\n",
        "        print(f\"  Total Loss:          {np.mean(total_losses):.3f} ¬± {np.std(total_losses):.3f}\")\n",
        "        print(f\"  Recon/KL Ratio:      {np.mean(recon_losses)/np.mean(kl_losses):.2f}\")\n",
        "    \n",
        "    # Interactive widget\n",
        "    interact(analyze_elbo_components,\n",
        "             num_samples=widgets.IntSlider(value=50, min=10, max=len(sample_images), step=10, description='# Samples:'),\n",
        "             beta=widgets.FloatSlider(value=1.0, min=0.1, max=5.0, step=0.1, description='Œ≤ (Beta):'))\n",
        "             \n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping ELBO analysis (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ 2D Latent Space Visualization (if applicable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è 2D visualization only available for 2D latent space. Current model has 32D latent space.\n"
          ]
        }
      ],
      "source": [
        "if model is not None and model.latent_dim == 2:\n",
        "    def visualize_2d_latent_space(num_samples=200):\n",
        "        \"\"\"Visualize 2D latent space.\"\"\"\n",
        "        model.eval()\n",
        "        \n",
        "        # Collect latent codes\n",
        "        latent_codes = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for i in range(min(num_samples, len(sample_images))):\n",
        "                x = sample_images[i:i+1].to(device)\n",
        "                mu, _ = model.encode(x)\n",
        "                latent_codes.append(mu.cpu().numpy())\n",
        "        \n",
        "        latent_codes = np.vstack(latent_codes)\n",
        "        \n",
        "        # Create visualization\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        \n",
        "        # Scatter plot of latent codes\n",
        "        axes[0].scatter(latent_codes[:, 0], latent_codes[:, 1], alpha=0.6, s=20)\n",
        "        axes[0].set_xlabel('Latent Dimension 1')\n",
        "        axes[0].set_ylabel('Latent Dimension 2')\n",
        "        axes[0].set_title('Learned Latent Representations')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Sample from a grid in latent space\n",
        "        n_grid = 10\n",
        "        x_range = np.linspace(-3, 3, n_grid)\n",
        "        y_range = np.linspace(-3, 3, n_grid)\n",
        "        \n",
        "        grid_samples = []\n",
        "        for x in x_range:\n",
        "            for y in y_range:\n",
        "                z = torch.tensor([[x, y]], dtype=torch.float32, device=device)\n",
        "                with torch.no_grad():\n",
        "                    sample = model.decode(z)\n",
        "                    if hasattr(model, 'decoder') and hasattr(model.decoder, 'deconv_layers'):\n",
        "                        sample = torch.sigmoid(sample)\n",
        "                    grid_samples.append(sample.cpu().numpy())\n",
        "        \n",
        "        # Create a mosaic of samples\n",
        "        mosaic = np.zeros((n_grid * sample_images.shape[-2], n_grid * sample_images.shape[-1]))\n",
        "        \n",
        "        for i, sample in enumerate(grid_samples):\n",
        "            row = i // n_grid\n",
        "            col = i % n_grid\n",
        "            \n",
        "            start_row = row * sample_images.shape[-2]\n",
        "            end_row = start_row + sample_images.shape[-2]\n",
        "            start_col = col * sample_images.shape[-1]\n",
        "            end_col = start_col + sample_images.shape[-1]\n",
        "            \n",
        "            mosaic[start_row:end_row, start_col:end_col] = sample[0].squeeze()\n",
        "        \n",
        "        axes[1].imshow(mosaic, cmap='gray', extent=[-3, 3, -3, 3])\n",
        "        axes[1].set_xlabel('Latent Dimension 1')\n",
        "        axes[1].set_ylabel('Latent Dimension 2')\n",
        "        axes[1].set_title('Latent Space Manifold')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Interactive widget\n",
        "    interact(visualize_2d_latent_space,\n",
        "             num_samples=widgets.IntSlider(value=100, min=50, max=min(500, len(sample_images)), step=50, description='# Samples:'))\n",
        "             \n",
        "elif model is not None:\n",
        "    print(f\"‚ÑπÔ∏è 2D visualization only available for 2D latent space. Current model has {model.latent_dim}D latent space.\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping 2D visualization (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Model Architecture Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèóÔ∏è Model Architecture Summary:\n",
            "  Model Type: VAEConv\n",
            "  Input Channels: 1\n",
            "  Latent Dimensions: 32\n",
            "  Base Channels: 64\n",
            "  Total Parameters: 5,611,713\n",
            "  Trainable Parameters: 5,611,713\n",
            "  Model Size: 21.42 MB\n",
            "\n",
            "üìã Training Configuration:\n",
            "  Dataset: mnist\n",
            "  Batch Size: 128\n",
            "  Learning Rate: 0.0003\n",
            "  Optimizer: adamw\n",
            "  Reconstruction Loss: bce\n",
            "  Beta (KL weight): 1.0\n",
            "  KL Schedule: linear\n",
            "  KL Warmup Epochs: 10\n"
          ]
        }
      ],
      "source": [
        "if model is not None:\n",
        "    print(\"üèóÔ∏è Model Architecture Summary:\")\n",
        "    print(f\"  Model Type: {model.__class__.__name__}\")\n",
        "    print(f\"  Input Channels: {model.in_channels}\")\n",
        "    print(f\"  Latent Dimensions: {model.latent_dim}\")\n",
        "    if hasattr(model, 'base_channels'):\n",
        "        print(f\"  Base Channels: {model.base_channels}\")\n",
        "    \n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    print(f\"  Total Parameters: {total_params:,}\")\n",
        "    print(f\"  Trainable Parameters: {trainable_params:,}\")\n",
        "    \n",
        "    # Model size\n",
        "    param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
        "    buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
        "    size_mb = (param_size + buffer_size) / (1024 * 1024)\n",
        "    \n",
        "    print(f\"  Model Size: {size_mb:.2f} MB\")\n",
        "    \n",
        "    print(\"\\nüìã Training Configuration:\")\n",
        "    print(f\"  Dataset: {config.data.dataset}\")\n",
        "    print(f\"  Batch Size: {config.data.batch_size}\")\n",
        "    print(f\"  Learning Rate: {config.train.lr}\")\n",
        "    print(f\"  Optimizer: {config.train.opt}\")\n",
        "    print(f\"  Reconstruction Loss: {config.train.recon_loss}\")\n",
        "    print(f\"  Beta (KL weight): {config.train.beta}\")\n",
        "    print(f\"  KL Schedule: {config.train.kl_schedule}\")\n",
        "    if config.train.kl_schedule != 'none':\n",
        "        print(f\"  KL Warmup Epochs: {config.train.kl_warmup_epochs}\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping architecture summary (model not available)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully explored the VAE latent space! Here's what you've learned:\n",
        "\n",
        "### üîç Key Insights\n",
        "- **Reconstruction Quality**: How well the VAE can reconstruct input images\n",
        "- **Latent Space Structure**: How different dimensions capture different aspects of the data\n",
        "- **ELBO Components**: The balance between reconstruction accuracy and regularization\n",
        "- **Generation Capability**: How the model can generate new samples from the learned distribution\n",
        "\n",
        "### üöÄ Next Steps\n",
        "1. **Experiment with Œ≤-VAE**: Try different Œ≤ values to see how it affects disentanglement\n",
        "2. **Compare Architectures**: Train different VAE architectures (CNN, ResNet, MLP) and compare\n",
        "3. **Try Different Datasets**: See how the VAE performs on CIFAR-10 vs MNIST\n",
        "4. **Posterior Collapse**: Investigate if any latent dimensions are being ignored (KL ‚âà 0)\n",
        "\n",
        "### üìö Further Reading\n",
        "- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114) - Original VAE paper\n",
        "- [Œ≤-VAE](https://openreview.net/forum?id=Sy2fzU9gl) - Learning Basic Visual Concepts with a Constrained Variational Framework\n",
        "- [Understanding disentangling in Œ≤-VAE](https://arxiv.org/abs/1804.03599)\n",
        "\n",
        "Happy experimenting! üß™‚ú®\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "generative",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
