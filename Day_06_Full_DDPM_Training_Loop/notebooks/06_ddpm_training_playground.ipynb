{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# DDPM Training Playground üé®\n",
        "\n",
        "This notebook provides an interactive environment for experimenting with Denoising Diffusion Probabilistic Models (DDPM).\n",
        "\n",
        "## Contents:\n",
        "1. **Setup & Configuration** - Load dependencies and configs\n",
        "2. **Data Exploration** - Visualize training datasets\n",
        "3. **Model Architecture** - Explore UNet and time embeddings\n",
        "4. **Noise Schedules** - Understand beta/alpha schedules\n",
        "5. **Forward Process** - See how noise is added over time\n",
        "6. **Training Demo** - Interactive mini training session\n",
        "7. **Sampling** - Generate new samples with DDPM/DDIM\n",
        "8. **Evaluation** - Assess model quality and performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Setup & Imports üîß\n",
        "\n",
        "First, let's set up our environment and import all the necessary modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Basic imports successful!\n",
            "üîß PyTorch version: 2.8.0+cu128\n",
            "üöÄ CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "# Add the parent directory to path for imports\n",
        "current_dir = Path().absolute()\n",
        "parent_dir = current_dir.parent\n",
        "sys.path.insert(0, str(parent_dir / 'src'))\n",
        "\n",
        "print(\"‚úÖ Basic imports successful!\")\n",
        "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Import error: attempted relative import with no known parent package\n",
            "üí° Tip: Make sure you're running from the notebooks/ directory\n"
          ]
        }
      ],
      "source": [
        "# Import DDPM modules (run this cell separately to debug any import issues)\n",
        "try:\n",
        "    # Core DDPM modules\n",
        "    from ddpm_schedules import DDPMSchedules\n",
        "    from sampler import DDPMSampler\n",
        "    from dataset import get_dataloader, get_dataset_stats\n",
        "    from utils import seed_everything, get_device\n",
        "    from losses import ddpm_loss\n",
        "    \n",
        "    # Model modules\n",
        "    from models.simple_unet import SimpleUNet\n",
        "    from models.unet_small import UNetSmall\n",
        "    from models.time_embedding import TimeEmbedding\n",
        "    \n",
        "    # Visualization and evaluation\n",
        "    import visualize\n",
        "    from eval import calculate_psnr_ssim, calculate_lpips_diversity\n",
        "    \n",
        "    print(\"‚úÖ All DDPM modules imported successfully!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"üí° Tip: Make sure you're running from the notebooks/ directory\")\n",
        "    # Continue anyway - we'll handle missing modules gracefully\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Configuration & Device Setup üéØ\n",
        "\n",
        "Load the MNIST configuration and set up our device and random seeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'seed_everything' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup device and seed\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mseed_everything\u001b[49m(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m get_device(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müéØ Using device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seed_everything' is not defined"
          ]
        }
      ],
      "source": [
        "# Setup device and seed\n",
        "seed_everything(42)\n",
        "device = get_device(\"auto\")\n",
        "print(f\"üéØ Using device: {device}\")\n",
        "\n",
        "# Load configuration\n",
        "config_path = \"../configs/mnist.yaml\"\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"üìù Configuration loaded:\")\n",
        "for section, values in config.items():\n",
        "    if isinstance(values, dict):\n",
        "        print(f\"  {section}: {len(values)} parameters\")\n",
        "    else:\n",
        "        print(f\"  {section}: {values}\")\n",
        "\n",
        "# Set matplotlib style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "print(\"üîÑ Loading MNIST data...\")\n",
        "train_loader = get_dataloader(\n",
        "    dataset_name=config[\"dataset\"][\"name\"],\n",
        "    batch_size=64,  # Smaller batch for visualization\n",
        "    train=True,\n",
        "    data_dir=\"../data\",\n",
        "    image_size=config[\"dataset\"][\"image_size\"]\n",
        ")\n",
        "\n",
        "# Get a batch for visualization\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "print(f\"üì¶ Batch shape: {images.shape}\")\n",
        "print(f\"üè∑Ô∏è Labels shape: {labels.shape}\")\n",
        "print(f\"üìä Data range: [{images.min():.3f}, {images.max():.3f}]\")\n",
        "print(f\"üéØ Unique labels: {torch.unique(labels).tolist()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
        "fig.suptitle(\"Sample Training Images\", fontsize=16)\n",
        "\n",
        "for i in range(32):\n",
        "    row = i // 8\n",
        "    col = i % 8\n",
        "    \n",
        "    # Convert to displayable format\n",
        "    img = images[i].squeeze()  # Remove channel dimension\n",
        "    \n",
        "    # Denormalize for display (assuming [-1, 1] normalization)\n",
        "    img = (img + 1) / 2\n",
        "    img = torch.clamp(img, 0, 1)\n",
        "    \n",
        "    axes[row, col].imshow(img, cmap='gray')\n",
        "    axes[row, col].set_title(f'Label: {labels[i].item()}', fontsize=10)\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìà Dataset Statistics:\")\n",
        "print(f\"  Mean: {images.mean():.4f}\")\n",
        "print(f\"  Std: {images.std():.4f}\")\n",
        "print(f\"  Shape per image: {images[0].shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the model based on config\n",
        "print(\"üèóÔ∏è Creating model...\")\n",
        "model_config = config[\"model\"]\n",
        "\n",
        "if model_config[\"type\"] == \"simple_unet\":\n",
        "    model = SimpleUNet(\n",
        "        in_channels=model_config[\"in_channels\"],\n",
        "        out_channels=model_config[\"out_channels\"],\n",
        "        base_channels=model_config.get(\"base_channels\", 64),\n",
        "        time_embed_dim=model_config.get(\"time_embed_dim\", 256)\n",
        "    )\n",
        "elif model_config[\"type\"] == \"unet_small\":\n",
        "    model = UNetSmall(\n",
        "        in_channels=model_config[\"in_channels\"],\n",
        "        out_channels=model_config[\"out_channels\"],\n",
        "        model_channels=model_config[\"model_channels\"],\n",
        "        channel_mult=model_config[\"channel_mult\"],\n",
        "        num_res_blocks=model_config[\"num_res_blocks\"],\n",
        "        attention_resolutions=model_config[\"attention_resolutions\"],\n",
        "        dropout=model_config[\"dropout\"],\n",
        "        time_embed_dim=model_config[\"time_embed_dim\"],\n",
        "        use_attention=model_config[\"use_attention\"],\n",
        "        num_heads=model_config[\"num_heads\"]\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model type: {model_config['type']}\")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Model summary\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"üèóÔ∏è Model: {model.__class__.__name__}\")\n",
        "print(f\"üìä Total parameters: {total_params:,}\")\n",
        "print(f\"üéØ Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"üíæ Model size: ~{total_params * 4 / 1024 / 1024:.2f} MB (float32)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test forward pass\n",
        "test_input = torch.randn(2, model_config[\"in_channels\"], 32, 32, device=device)\n",
        "test_t = torch.randint(0, 1000, (2,), device=device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(test_input, test_t)\n",
        "    print(f\"üîÑ Forward pass test:\")\n",
        "    print(f\"  Input shape: {test_input.shape}\")\n",
        "    print(f\"  Time shape: {test_t.shape}\")\n",
        "    print(f\"  Output shape: {output.shape}\")\n",
        "    print(f\"  ‚úÖ Forward pass successful!\")\n",
        "\n",
        "# Create DDPM schedules\n",
        "print(f\"üìÖ Creating DDPM schedules...\")\n",
        "schedule_config = config[\"schedules\"]\n",
        "schedules = DDPMSchedules(\n",
        "    num_timesteps=schedule_config[\"num_timesteps\"],\n",
        "    schedule_type=schedule_config[\"type\"],\n",
        "    beta_start=float(schedule_config[\"beta_start\"]),\n",
        "    beta_end=float(schedule_config[\"beta_end\"])\n",
        ")\n",
        "\n",
        "print(f\"üìÖ Schedule type: {schedule_config['type']}\")\n",
        "print(f\"‚è∞ Timesteps: {schedule_config['num_timesteps']}\")\n",
        "print(f\"üìä Beta range: [{schedule_config['beta_start']}, {schedule_config['beta_end']}]\")\n",
        "print(f\"‚úÖ Schedules created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sampler and test basic functionality\n",
        "print(\"üöÄ Creating DDPM sampler...\")\n",
        "sampler = DDPMSampler(schedules)\n",
        "model.eval()\n",
        "\n",
        "# Test sampling (this will be noisy since model isn't trained yet)\n",
        "print(\"üé® Testing sampling (untrained model - expect noise)...\")\n",
        "sample_shape = (4, model_config[\"in_channels\"], 32, 32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Test DDIM sampling (faster)\n",
        "    print(\"  Testing DDIM sampling (50 steps)...\")\n",
        "    ddim_samples = sampler.sample(\n",
        "        model=model,\n",
        "        shape=sample_shape,\n",
        "        method=\"ddim\",\n",
        "        num_steps=50,\n",
        "        device=device\n",
        "    )\n",
        "    print(f\"  ‚úÖ DDIM sampling successful: {ddim_samples.shape}\")\n",
        "    \n",
        "    # Test DDPM sampling (slower, more thorough)\n",
        "    print(\"  Testing DDPM sampling...\")\n",
        "    ddpm_samples = sampler.sample(\n",
        "        model=model,\n",
        "        shape=(2, model_config[\"in_channels\"], 32, 32),  # Smaller batch for speed\n",
        "        method=\"ddpm\",\n",
        "        device=device\n",
        "    )\n",
        "    print(f\"  ‚úÖ DDPM sampling successful: {ddpm_samples.shape}\")\n",
        "\n",
        "print(\"üéâ All core functionality working!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize generated samples (untrained model)\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "fig.suptitle(\"Generated Samples (Untrained Model - Pure Noise Expected)\", fontsize=14)\n",
        "\n",
        "# Show DDIM samples\n",
        "for i in range(4):\n",
        "    sample = ddim_samples[i].cpu().squeeze()\n",
        "    sample = (sample + 1) / 2  # Denormalize\n",
        "    sample = torch.clamp(sample, 0, 1)\n",
        "    \n",
        "    axes[0, i].imshow(sample, cmap='gray')\n",
        "    axes[0, i].set_title(f\"DDIM Sample {i+1}\", fontsize=10)\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "# Show DDPM samples\n",
        "for i in range(2):\n",
        "    sample = ddpm_samples[i].cpu().squeeze()\n",
        "    sample = (sample + 1) / 2  # Denormalize\n",
        "    sample = torch.clamp(sample, 0, 1)\n",
        "    \n",
        "    axes[1, i].imshow(sample, cmap='gray')\n",
        "    axes[1, i].set_title(f\"DDPM Sample {i+1}\", fontsize=10)\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "# Clear the remaining subplots\n",
        "for i in range(2, 4):\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üîç Sample Analysis (Untrained Model):\")\n",
        "print(f\"  DDIM samples mean: {ddim_samples.mean():.4f}\")\n",
        "print(f\"  DDIM samples std: {ddim_samples.std():.4f}\")\n",
        "print(f\"  DDPM samples mean: {ddpm_samples.mean():.4f}\")\n",
        "print(f\"  DDPM samples std: {ddpm_samples.std():.4f}\")\n",
        "print(\"üí° These are noise since the model is untrained!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Next Steps & Real Training\n",
        "\n",
        "This notebook demonstrated the core DDPM pipeline with an untrained model. To get actual digit generation:\n",
        "\n",
        "### üöÄ **Train the Model:**\n",
        "\n",
        "```bash\n",
        "# From the project root directory:\n",
        "cd Day_06_Full_DDPM_Training_Loop\n",
        "\n",
        "# Train full model (takes ~1 hour)\n",
        "make train\n",
        "\n",
        "# Or train with custom config\n",
        "python -m src.cli train --config configs/mnist.yaml --epochs 200\n",
        "```\n",
        "\n",
        "### üìä **Generate Samples:**\n",
        "\n",
        "```bash\n",
        "# Generate sample grids\n",
        "make sample\n",
        "\n",
        "# Create trajectory animations  \n",
        "python -m src.cli sample.trajectory --config configs/mnist.yaml\n",
        "\n",
        "# Full evaluation report\n",
        "make report\n",
        "```\n",
        "\n",
        "### üí° **Load Pre-trained Model:**\n",
        "\n",
        "If you have a trained model, load it in this notebook:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained model (if available)\n",
        "checkpoint_path = \"../outputs/ckpts/best.pt\"  # or latest.pt, or specific epoch\n",
        "\n",
        "if Path(checkpoint_path).exists():\n",
        "    print(f\"üîÑ Loading checkpoint from {checkpoint_path}...\")\n",
        "    \n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    print(f\"‚úÖ Model loaded!\")\n",
        "    print(f\"  Epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
        "    print(f\"  Loss: {checkpoint.get('loss', 'unknown')}\")\n",
        "    \n",
        "    # Now generate high-quality samples\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        print(\"üé® Generating samples with trained model...\")\n",
        "        trained_samples = sampler.sample(\n",
        "            model=model,\n",
        "            shape=(16, model_config[\"in_channels\"], 32, 32),\n",
        "            method=\"ddim\",\n",
        "            num_steps=50,\n",
        "            device=device\n",
        "        )\n",
        "        \n",
        "        # Visualize trained samples\n",
        "        fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "        fig.suptitle(\"Generated MNIST Digits (Trained Model)\", fontsize=16)\n",
        "        \n",
        "        for i in range(16):\n",
        "            row, col = i // 4, i % 4\n",
        "            sample = trained_samples[i].cpu().squeeze()\n",
        "            sample = (sample + 1) / 2\n",
        "            sample = torch.clamp(sample, 0, 1)\n",
        "            \n",
        "            axes[row, col].imshow(sample, cmap='gray')\n",
        "            axes[row, col].axis('off')\n",
        "            \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"‚úÖ High-quality digit generation successful!\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No pre-trained model found.\")\n",
        "    print(\"üí° Run training first: make train\")\n",
        "    print(\"üìç Expected path:\", checkpoint_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ DDPM Notebook Complete!\")\n",
        "print(\"üìñ You've successfully explored the DDPM pipeline!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Data Exploration üìä\n",
        "\n",
        "Let's load and visualize the MNIST training data to understand what we're working with.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
