# Day 4: Forward Diffusion Process ğŸŒŠ

A complete implementation of the forward diffusion process for DDPMs, featuring interactive visualizations, comprehensive statistical analysis, and multiple noise schedules.

## ğŸ¯ Overview

This implementation provides a deep dive into the mathematical foundation of diffusion models through the forward noising process. You can explore how images gradually transform from clean data to pure noise, analyze different noise schedules, and understand the statistical properties that make DDPMs work.

## âœ¨ Key Features

- **ğŸ“ˆ Multiple Noise Schedules**: Linear, cosine, and sigmoid schedules with comparative analysis
- **ğŸ¨ Interactive Visualizations**: Trajectory grids, animations, and real-time parameter tuning
- **ğŸ“Š Statistical Analysis**: SNR tracking, MSE/KL convergence, pixel distribution evolution  
- **ğŸ§ª Comprehensive Testing**: Unit tests for mathematical correctness and edge cases
- **ğŸ’» CLI Interface**: Complete command-line tools for batch processing
- **ğŸ““ Interactive Notebook**: Jupyter notebook with widgets for exploration

## ğŸš€ Quick Start

### Installation
```bash
# Install dependencies
make install

# Or manually
pip install -r requirements.txt
pip install -e .
```

### Run Experiments
```bash
# Generate all MNIST results
make run-mnist

# Generate all CIFAR-10 results  
make run-cifar10

# Run both datasets
make run-all
```

### Interactive Exploration
```bash
# Launch Jupyter notebook
make notebook

# Or directly
jupyter lab notebooks/04_forward_diffusion.ipynb
```

## ğŸ—‚ï¸ Project Structure

```
Day_04_Forward_Diffusion_Process/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ pyproject.toml             # Package configuration
â”œâ”€â”€ Makefile                   # Build automation
â”œâ”€â”€ configs/                   # YAML configurations
â”‚   â”œâ”€â”€ mnist.yaml            # MNIST experiment settings
â”‚   â””â”€â”€ cifar10.yaml          # CIFAR-10 experiment settings
â”œâ”€â”€ src/                       # Core implementation
â”‚   â”œâ”€â”€ utils.py              # Utilities (seed, device, normalization)
â”‚   â”œâ”€â”€ dataset.py            # MNIST/CIFAR loaders
â”‚   â”œâ”€â”€ ddpm_schedules.py     # Noise schedule implementations
â”‚   â”œâ”€â”€ forward.py            # Forward diffusion mathematics
â”‚   â”œâ”€â”€ stats.py              # Statistical analysis
â”‚   â”œâ”€â”€ visualize.py          # Plotting and animation
â”‚   â””â”€â”€ cli.py                # Command-line interface
â”œâ”€â”€ scripts/                   # Automation scripts
â”‚   â”œâ”€â”€ run_mnist.sh          # One-click MNIST experiments
â”‚   â”œâ”€â”€ run_cifar10.sh        # One-click CIFAR-10 experiments
â”‚   â””â”€â”€ make_figures.sh       # Custom figure generation
â”œâ”€â”€ notebooks/                 # Interactive exploration
â”‚   â””â”€â”€ 04_forward_diffusion.ipynb
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ test_schedules.py     # Schedule validation
â”‚   â”œâ”€â”€ test_forward_xt_x0.py # Forward process tests
â”‚   â””â”€â”€ test_visualize.py     # Visualization tests
â””â”€â”€ outputs/                   # Generated results
    â”œâ”€â”€ grids/                # Trajectory visualizations
    â”œâ”€â”€ animations/           # Diffusion animations
    â”œâ”€â”€ plots/                # Statistical plots
    â””â”€â”€ logs/                 # CSV data logs
```

## ğŸ§® Mathematical Implementation

### Forward Process
- **Sequential**: `q(x_t|x_{t-1}) = N(x_t; âˆš(1-Î²_t)x_{t-1}, Î²_t I)`
- **Closed-form**: `q(x_t|x_0) = N(x_t; âˆš(á¾±_t)x_0, (1-á¾±_t)I)`  
- **Cumulative**: `á¾±_t = âˆ_{s=1}^t Î±_s` where `Î±_s = 1 - Î²_s`

### Noise Schedules
- **Linear**: `Î²_t` increases linearly from `Î²_1` to `Î²_T`
- **Cosine**: Smooth S-curve based on cosine function for gradual noise addition
- **Sigmoid**: Steep middle transition with gentle start/end

### Statistical Analysis
- **SNR**: Signal-to-noise ratio `á¾±_t / (1 - á¾±_t)` tracked in dB
- **MSE**: Mean squared error between `x_t` and `x_0`
- **KL Divergence**: `KL(q(x_t|x_0) || N(0,I))` convergence measurement

## ğŸ’» Usage Examples

### CLI Commands
```bash
# Individual experiments
python -m src.cli traj.grid --config configs/mnist.yaml
python -m src.cli traj.animate --config configs/cifar10.yaml --idx 5
python -m src.cli plots.schedules --config configs/mnist.yaml
python -m src.cli plots.snr --config configs/cifar10.yaml
python -m src.cli plots.hist --config configs/mnist.yaml

# Batch processing
python -m src.cli run.all --config configs/mnist.yaml
```

### Makefile Targets
```bash
# Development
make test          # Run test suite
make lint          # Check code quality
make clean         # Clean outputs

# Experiments
make trajectory-grid DATASET=mnist
make plot-schedules DATASET=cifar10
make figures DATASET=mnist  # Custom figure bundle

# Convenience
make quick-mnist   # Fast trajectory + schedules
make examples      # Show usage examples
```

### Python API
```python
from src.ddpm_schedules import get_ddpm_schedule
from src.forward import q_xt_given_x0, sample_trajectory
from src.visualize import create_trajectory_grid

# Get noise schedule
betas, alphas, alpha_bars = get_ddpm_schedule(1000, "cosine")

# Sample at specific time step
x_t, noise = q_xt_given_x0(x0, t, alpha_bars)

# Create full trajectory
trajectory = sample_trajectory(x0, 1000, betas, alpha_bars)

# Visualize results
create_trajectory_grid(x0, [0, 100, 500, 999], alpha_bars, "trajectory.png")
```

## ğŸ“Š Expected Outputs

After running experiments, you'll find:

### Visualizations
- **`outputs/grids/mnist_traj_grid.png`**: 16 images Ã— selected time steps
- **`outputs/animations/sample_000.gif`**: Single image diffusion animation
- **`outputs/plots/beta_alpha_snr.png`**: Schedule comparison curves
- **`outputs/plots/hist_t_cosine.png`**: Pixel distribution evolution

### Data Logs
- **`outputs/logs/forward_stats.csv`**: Complete statistical time series
  - Columns: `[t, beta, alpha_bar, snr_db, mse_to_x0, kl_to_unit]`

### Analysis Results
- **SNR Thresholds**: When images become more noise than signal
- **Schedule Efficiency**: Comparative time-to-threshold analysis
- **Convergence Verification**: Statistical validation of N(0,1) convergence

## ğŸ“ Key Insights

### Schedule Comparison
- **Cosine**: Gradual noise addition, preserves structure longer
- **Linear**: Uniform progression, standard DDPM default
- **Sigmoid**: Sharp middle transition, aggressive noise addition

### Critical Time Steps  
- **t â‰ˆ 200-400**: Image structure begins degrading significantly
- **SNR = -5dB**: Typical "more noise than signal" threshold
- **t â‰ˆ 800+**: Convergence to pure Gaussian noise

### Mathematical Verification
- **MSE Convergence**: Approaches `1 - á¾±_t` for unit-variance data
- **Pixel Statistics**: Mean â†’ 0, Std â†’ 1 as t â†’ T
- **Distribution Shape**: Gradual transformation to standard Gaussian

## ğŸ§ª Testing

Run the comprehensive test suite:
```bash
make test                    # Full test suite
make test-coverage          # With coverage report
pytest tests/ -v           # Verbose output
pytest tests/test_schedules.py  # Specific module
```

Tests verify:
- âœ… Schedule monotonicity and boundary conditions  
- âœ… Forward sampling mathematical correctness
- âœ… Statistical convergence properties
- âœ… Visualization output generation

## ğŸ”§ Development

### Code Quality
```bash
make format     # Auto-format with black/isort
make lint       # Check with flake8
make check      # Format + lint + test
```

### Interactive Development
```bash
make notebook   # Launch Jupyter Lab
make dev-setup  # Install development dependencies
```

## ğŸ“š Mathematical Background

This implementation follows the mathematical framework from:
- **Ho et al. (2020)**: "Denoising Diffusion Probabilistic Models" 
- **Sohl-Dickstein et al. (2015)**: "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"

Key mathematical concepts:
- Markov chain forward process
- Gaussian reparameterization trick
- Signal-to-noise ratio analysis  
- Statistical convergence theory

## ğŸ¤ Contributing

The implementation is modular and extensible:
- Add new noise schedules in `ddpm_schedules.py`
- Extend statistical analysis in `stats.py`
- Create custom visualizations in `visualize.py`
- Add dataset support in `dataset.py`

## ğŸ¯ Next Steps

This implementation prepares you for:
- **Day 5**: Reverse process and denoising
- **Day 6**: Complete DDPM training loop
- **Day 7**: Advanced sampling techniques

---

**â±ï¸ Time Investment**: 3-4 hours to explore fully  
**ğŸ¯ Difficulty**: â­â­â­â˜†â˜† (Mathematical foundations)  
**ğŸ”— Prerequisite**: Basic understanding of Gaussian processes