# Day 5: Reverse Process Intuition

**Complete DDPM implementation with reverse diffusion, UNet denoising, and comprehensive evaluation tools.**

---

## ğŸ¯ Objective

Build intuition for the reverse diffusion process through a complete DDPM implementation. This project focuses on understanding how neural networks learn to invert the noise addition process, with modern features like mixed precision training, EMA, and multiple sampling algorithms.

## ğŸ“‹ What You'll Learn

### Core DDPM Concepts
- **Forward vs Reverse Process**: How diffusion adds noise and how we learn to remove it
- **Noise Scheduling**: Linear, cosine, and quadratic beta schedules
- **Neural Parameterization**: Different ways to parameterize the denoising function (Îµ, xâ‚€, v)
- **Time Conditioning**: How to make neural networks aware of the noise level

### Implementation Skills  
- **UNet Architecture**: Time-conditioned U-Net with attention and FiLM normalization
- **Training Loop**: Modern training with AMP, EMA, gradient clipping, and learning rate scheduling
- **Sampling Algorithms**: Both DDPM ancestral sampling and DDIM deterministic sampling
- **Evaluation Metrics**: PSNR, SSIM, LPIPS for quantitative assessment

## ğŸ—ï¸ Project Structure

```
Day_05_Reverse_Process_Intuition/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ pyproject.toml               # Project configuration
â”œâ”€â”€ Makefile                     # Common commands
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ mnist.yaml              # MNIST training config
â”‚   â””â”€â”€ cifar10.yaml            # CIFAR-10 training config
â”œâ”€â”€ data/                       # Auto-downloaded datasets
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py                # Utilities: seed, device, checkpoints, EMA
â”‚   â”œâ”€â”€ dataset.py              # Dataset loaders with normalization
â”‚   â”œâ”€â”€ ddpm_schedules.py       # Beta schedules, alpha computations
â”‚   â”œâ”€â”€ losses.py               # Îµ-pred, xâ‚€-pred, v-pred losses
â”‚   â”œâ”€â”€ trainer.py              # Training loop with AMP, EMA, logging
â”‚   â”œâ”€â”€ sampler.py              # DDPM and DDIM sampling algorithms
â”‚   â”œâ”€â”€ eval.py                 # PSNR, SSIM, LPIPS evaluation
â”‚   â”œâ”€â”€ visualize.py            # Trajectory grids, animations, comparisons
â”‚   â”œâ”€â”€ compare_forward_reverse.py  # Day 4 vs Day 5 comparison
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ time_embedding.py   # Sinusoidal time embeddings + FiLM
â”‚   â”‚   â””â”€â”€ unet_tiny.py        # Lightweight UNet with time conditioning
â”‚   â””â”€â”€ cli.py                  # Command-line interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_mnist.sh          # Train on MNIST
â”‚   â”œâ”€â”€ train_cifar10.sh        # Train on CIFAR-10
â”‚   â”œâ”€â”€ sample_trajectories.sh  # Generate trajectory visualizations
â”‚   â””â”€â”€ make_figures.sh         # Generate all figures
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 05_reverse_process_playground.ipynb  # Interactive exploration
â”œâ”€â”€ outputs/                    # Generated content
â”‚   â”œâ”€â”€ ckpts/                  # Model checkpoints
â”‚   â”œâ”€â”€ logs/                   # Tensorboard logs
â”‚   â”œâ”€â”€ grids/                  # Trajectory and comparison grids
â”‚   â”œâ”€â”€ animations/             # GIF/MP4 reverse process animations
â”‚   â”œâ”€â”€ samples/                # Generated sample grids
â”‚   â””â”€â”€ reports/                # Evaluation reports and analysis
â””â”€â”€ tests/
    â”œâ”€â”€ test_unet_tiny.py       # Model architecture tests
    â”œâ”€â”€ test_loss_and_train.py  # Training pipeline tests
    â”œâ”€â”€ test_sampler_shapes.py  # Sampling algorithm tests
    â””â”€â”€ test_visualize.py       # Visualization tests
```

## ğŸš€ Quick Start

### 1. Installation
```bash
# Clone and enter the directory
cd Day_05_Reverse_Process_Intuition

# Install dependencies
pip install -r requirements.txt
# or
make install
```

### 2. Train Your First Model
```bash
# Quick MNIST training (5-10 minutes)
make train-mnist-quick

# Full MNIST training
scripts/train_mnist.sh

# CIFAR-10 training (requires GPU, 30+ minutes)
scripts/train_cifar10.sh
```

### 3. Generate Visualizations
```bash
# Generate all figures and analysis
scripts/make_figures.sh

# Or individual commands:
python -m src.cli sample.grid --ckpt outputs/ckpts/model_latest.pth
python -m src.cli sample.traj --ckpt outputs/ckpts/model_latest.pth --animation
python -m src.cli viz.compare --ckpt outputs/ckpts/model_latest.pth --report
```

### 4. Interactive Exploration
```bash
jupyter notebook notebooks/05_reverse_process_playground.ipynb
```

## ğŸ“Š Key Equations & Concepts

### Forward Process (Day 4 â†’ Day 5 Connection)
The forward process adds noise according to:
```
q(x_t | x_{t-1}) = N(x_t; âˆš(1-Î²_t) x_{t-1}, Î²_t I)
x_t = âˆšá¾±_t x_0 + âˆš(1-á¾±_t) Îµ,  where Îµ ~ N(0,I)
```

### Reverse Process (What We Learn)
The reverse process removes noise:
```
p_Î¸(x_{t-1} | x_t) = N(x_{t-1}; Î¼_Î¸(x_t, t), Ïƒ_t I)
Î¼_Î¸(x_t, t) = 1/âˆšÎ±_t (x_t - Î²_t/âˆš(1-á¾±_t) Îµ_Î¸(x_t, t))
```

### Training Objective (Simple DDPM Loss)
```
L = E_{t,x_0,Îµ} [||Îµ - Îµ_Î¸(x_t, t)||Â²]
```

Where:
- `Îµ_Î¸` is our neural network (UNet) that predicts noise
- `t` is sampled uniformly from {1, 2, ..., T}
- `x_t` is created by adding noise to `x_0`

## ğŸ¨ Generated Artifacts

After training, you'll have:

### Visual Outputs
- **Trajectory Grids**: Step-by-step reverse diffusion visualization
- **Sample Grids**: 64+ clean samples generated from noise  
- **Animations**: GIF/MP4 showing the denoising process
- **Forward vs Reverse**: Side-by-side comparison with Day 4

### Analysis Reports
- **Evaluation Metrics**: PSNR/SSIM reconstruction quality
- **Comparison Reports**: Forward vs reverse process analysis
- **Training Logs**: Loss curves and sample evolution

### Model Checkpoints
- **EMA Weights**: Exponential moving average for stable sampling
- **Training State**: Full checkpoint with optimizer state
- **Configuration**: Saved hyperparameters for reproducibility

## ğŸ”§ Advanced Usage

### Custom Training
```bash
python -m src.cli train \
    --config configs/mnist.yaml \
    --epochs 50 \
    --batch-size 256 \
    --learning-rate 1e-4
```

### Different Sampling Methods
```bash
# DDPM ancestral sampling (stochastic, high quality)
python -m src.cli sample.grid --sampler ddpm --num-samples 64

# DDIM sampling (deterministic, fast)
python -m src.cli sample.grid --sampler ddim --steps 20 --num-samples 64
```

### Comprehensive Evaluation
```bash
python -m src.cli eval \
    --ckpt outputs/ckpts/model_best.pth \
    --num-samples 1000 \
    --sampler ddpm
```

## ğŸ“ˆ Expected Results

### MNIST Results
- **Training Time**: 5-15 minutes on GPU
- **Model Size**: ~500K parameters  
- **Sample Quality**: Clean digit generation
- **PSNR**: 25+ dB reconstruction quality

### CIFAR-10 Results  
- **Training Time**: 30+ minutes on GPU
- **Model Size**: ~5M parameters
- **Sample Quality**: Recognizable objects with some artifacts
- **PSNR**: 20+ dB reconstruction quality

## ğŸ“ Learning Outcomes

By completing this project, you'll understand:

âœ… **How reverse diffusion works**: The mathematical relationship between forward and reverse processes

âœ… **Neural network denoising**: How time-conditioned UNets learn to predict and remove noise

âœ… **Training dynamics**: Why EMA, mixed precision, and proper scheduling matter for diffusion models  

âœ… **Sampling trade-offs**: Speed vs quality differences between DDPM and DDIM

âœ… **Evaluation methods**: Quantitative metrics for generative model assessment

## ğŸš¨ Common Issues & Solutions

### Training Issues
- **GPU Memory**: Reduce batch size or model channels in config
- **Slow Training**: Use mixed precision (`mixed_precision: true`)
- **Poor Samples**: Train longer or adjust learning rate

### Sampling Issues  
- **Blurry Samples**: Use EMA weights or increase model capacity
- **Mode Collapse**: Try different beta schedules (cosine vs linear)
- **Slow Sampling**: Use DDIM with fewer steps (20-50)

### Technical Issues
- **Import Errors**: Ensure you're in the project root directory
- **Missing Data**: Datasets auto-download on first use
- **Checkpoint Issues**: Check file paths and device compatibility

## ğŸ“š References & Further Reading

- **DDPM Paper**: "Denoising Diffusion Probabilistic Models" (Ho et al., 2020)
- **DDIM Paper**: "Denoising Diffusion Implicit Models" (Song et al., 2021)  
- **Score Matching**: "Generative Modeling by Estimating Gradients" (Song & Ermon, 2019)
- **UNet Architecture**: "U-Net: Convolutional Networks for Biomedical Image Segmentation" (Ronneberger et al., 2015)

## ğŸ¤ Acknowledgments

This implementation builds upon concepts from Day 4 (Forward Process) and provides a complete educational framework for understanding modern diffusion models.

---

**Time Estimate**: 2-4 hours (exploration + training)  
**Difficulty**: â­â­â­â­â˜†
**Prerequisites**: Day 4 (Forward Diffusion Process)